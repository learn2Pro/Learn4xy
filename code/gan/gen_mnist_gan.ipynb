{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#build the gan\n",
    "#first import all the shit from Keras\n",
    "\n",
    "from keras import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras import initializers\n",
    "\n",
    "#we will feed in a vector with 100 (or however many we want) elements of random noise\n",
    "noise_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator\n",
    "#del gen\n",
    "gen = Sequential()\n",
    "gen.add(Dense(128, activation='relu',\n",
    "              input_shape=(noise_dim,),\n",
    "              kernel_initializer='he_normal'))\n",
    "gen.add(Dropout(0.05))  #dropout helps a little, but also trains a little slower\n",
    "gen.add(Dense(784, activation='tanh',\n",
    "              kernel_initializer='he_normal'))\n",
    "gen.compile(optimizer='adam', loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator\n",
    "#del dis\n",
    "dis = Sequential()\n",
    "dis.add(Dense(128, activation='relu',\n",
    "              input_shape=(784,),\n",
    "              kernel_initializer='he_normal'))\n",
    "#dis.add(Dense(128, activation= 'selu',kernel_initializer= 'he_normal'))\n",
    "dis.add(Dense(1, activation='sigmoid',\n",
    "              kernel_initializer='he_normal'))\n",
    "dis.compile(optimizer='adam', loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined network\n",
    "#del gan\n",
    "dis.trainable = False\n",
    "ganInput = Input(shape=(noise_dim,))\n",
    "x = gen(ganInput)\n",
    "ganOutput = dis(x)\n",
    "gan = Model(inputs = ganInput, outputs = ganOutput)\n",
    "gan.compile(loss='binary_crossentropy',optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the generated images\n",
    "\n",
    "def plotGeneratedImages(examples=100, dim=(10, 10), figsize=(9, 9)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, noise_dim])\n",
    "    generatedImages = gen.predict(noise)\n",
    "    generatedImages = generatedImages.reshape(examples, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generatedImages.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i + 1)\n",
    "        plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLossesplotLoss():\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(DisLossHist, label='Discriminitive loss')\n",
    "    plt.plot(GenLossHist, label='Generative loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize a couple of lists to store the losses of the generator and discriminator (useful for plotting)\n",
    "DisLossHist = []\n",
    "GenLossHist = []\n",
    "\n",
    "currentPath = os.path.abspath('.')\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data(\n",
    "    currentPath + \"/data/mnist.npz\")\n",
    "\n",
    "\n",
    "plt.imshow(x_train[0], cmap='gray')\n",
    "plt.title('Class ' + str(y_train[0]))\n",
    "num_classes = 10\n",
    "input_unit_size = 28 * 28\n",
    "\n",
    "\n",
    "##归一化数据\n",
    "x_train = x_train.reshape(x_train.shape[0], input_unit_size)\n",
    "x_test = x_test.reshape(x_test.shape[0], input_unit_size)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "def train(epochs=1, batchSize=128):\n",
    "    batchCount = int(x_train.shape[0] / batchSize)\n",
    "\n",
    "    np.random.shuffle(x_train)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        if e % 2 == 0:\n",
    "            print(\"epoch \", e)\n",
    "        for b in range(batchCount):\n",
    "            #if b % 20 == 0:\n",
    "            #    print(\"step \",b)\n",
    "\n",
    "            #first pass through the loop, b is 0!\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, noise_dim])\n",
    "            imageBatch = x_train[b * batchSize:(b + 1) * batchSize, :]\n",
    "\n",
    "            #generate fake images\n",
    "            generatedImages = gen.predict(noise)\n",
    "\n",
    "            #append a batch of real images to fake images\n",
    "            discriminatorInputs = np.vstack((imageBatch, generatedImages))\n",
    "\n",
    "            #create labels for the disciminator inputs\n",
    "            yDis = np.zeros(2 * batchSize)\n",
    "            yDis[:batchSize] = 0.9\n",
    "\n",
    "            #train Discriminator\n",
    "            dis.trainable = True\n",
    "            dLoss = dis.train_on_batch(discriminatorInputs, yDis)\n",
    "\n",
    "            #train Generator\n",
    "            dis.trainable = False\n",
    "            yGen = np.ones(batchSize)\n",
    "            gLoss = gan.train_on_batch(noise, yGen)\n",
    "\n",
    "        DisLossHist.append(dLoss)\n",
    "        GenLossHist.append(gLoss)\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(epochs = 100, batchSize = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLossesplotLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotGeneratedImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModels():\n",
    "    gen.save('gan_generator_twos.h5')\n",
    "    dis.save('dis_generator_twos.h5')\n",
    "\n",
    "saveModels()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
